{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21aaf3ea-5e47-44f5-9885-dc73a12e4216",
   "metadata": {},
   "source": [
    "# ETL Master Flight Table Using Dask\n",
    "The master flight table combines attributes from external tables to form a single flat table to use as a starting point for training our ML models. External attribute tables such as airport demand and weather can be pre-partitioned by airport name. External tables are typically joined to the master flight table twice: once for arrivals and a second time for departures. Data alignment is required to merge these tables so multiple shuffle operations are required for each of the joins. Pre-partitioning the data ensures that the dominant join pattern can take advantage of less expensive, in-block operations to avoid unnecessary data movement. This becomes critical for large datasets on a distributed cluster environment.  \n",
    "\n",
    "Dask 2021.06.0 doesn't currently support MultiIndex so multi-index merging on [ARPT_NAME, DEP_TIME_DT_LOCAL_HR] is not optimal. Creating dask index or running groupby requires shuffling when join attributes are not indexed. Performing indexing before merge should save memory usage at the expense of additional computational overhead to create such indices. Some recommendations are provided in the dask documenation: https://docs.dask.org/en/latest/dataframe-best-practices.html#repartition-to-reduce-overhead  \n",
    "> dd.merge(a, pandas_df)  # fast  \n",
    "dd.merge(a, b, left_index=True, right_index=True)  # fast  \n",
    "dd.merge(a, b, left_index=True, right_on='id')  # half-fast, half-slow  \n",
    "dd.merge(a, b, left_on='id', right_on='id')  # slow  \n",
    "\n",
    "Hand tuning data flows requires a deep understanding of internal data structures. Operations that worked for small data samples may not be scalable to the full dataset. This provides some motivation to try to improve performance using advanced libraries such as Spark, dask, or NVTabular to enable us to reuse simple code and scale it to the full dataset without having to resort to writing additional custom code or patches for resolving performance issues at scale. Some fine-tuning is required to get dask to run well at scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04872737-489c-4527-87de-9e6b0e81299d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask version 2021.06.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/distributed/node.py:160: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 43583 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div style=\"\n",
       "                    width: 24px;\n",
       "                    height: 24px;\n",
       "                    background-color: #e1e1e1;\n",
       "                    border: 3px solid #9D9D9D;\n",
       "                    border-radius: 5px;\n",
       "                    position: absolute;\"> </div>\n",
       "                <div style=\"margin-left: 48px;\">\n",
       "                    <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "                    <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-24ea38b2-df9e-11eb-900d-9b853caa0319</p>\n",
       "                    <table style=\"width: 100%; text-align: left;\">\n",
       "                    \n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "                    <td style=\"text-align: left;\"><strong>Cluster type:</strong> LocalCluster</td>\n",
       "                </tr>\n",
       "                \n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard: </strong>\n",
       "                        <a href=\"http://127.0.0.1:43583/status\">http://127.0.0.1:43583/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\"></td>\n",
       "                </tr>\n",
       "                \n",
       "                    </table>\n",
       "                    \n",
       "                <details>\n",
       "                <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "                \n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "                <div style=\"\n",
       "                    width: 24px;\n",
       "                    height: 24px;\n",
       "                    background-color: #e1e1e1;\n",
       "                    border: 3px solid #9D9D9D;\n",
       "                    border-radius: 5px;\n",
       "                    position: absolute;\"> </div>\n",
       "                <div style=\"margin-left: 48px;\">\n",
       "                    <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LocalCluster</h3>\n",
       "                    <p style=\"color: #9D9D9D; margin-bottom: 0px;\">d9bd3cde</p>\n",
       "                    <table style=\"width: 100%; text-align: left;\">\n",
       "                    \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\"><strong>Status:</strong> running</td>\n",
       "                <td style=\"text-align: left;\"><strong>Using processes:</strong> True</td>\n",
       "            </tr>\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:43583/status\">http://127.0.0.1:43583/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"><strong>Workers:</strong> 1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong>\n",
       "                    32\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong>\n",
       "                    251.65 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "                    </table>\n",
       "                    <details>\n",
       "                    <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Scheduler Info</h3></summary>\n",
       "                    \n",
       "        <div style=\"\">\n",
       "            \n",
       "            <div>\n",
       "                <div style=\"\n",
       "                    width: 24px;\n",
       "                    height: 24px;\n",
       "                    background-color: #FFF7E5;\n",
       "                    border: 3px solid #FF6132;\n",
       "                    border-radius: 5px;\n",
       "                    position: absolute;\"> </div>\n",
       "                <div style=\"margin-left: 48px;\">\n",
       "                    <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "                    <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-f009ea02-02f6-41f9-bbbc-53f2e920938a</p>\n",
       "                    <table style=\"width: 100%; text-align: left;\">\n",
       "                        <tr>\n",
       "                            <td style=\"text-align: left;\"><strong>Comm:</strong> tcp://127.0.0.1:38995</td>\n",
       "                            <td style=\"text-align: left;\"><strong>Workers:</strong> 1</td>\n",
       "                        </tr>\n",
       "                        <tr>\n",
       "                            <td style=\"text-align: left;\">\n",
       "                                <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:43583/status\">http://127.0.0.1:43583/status</a>\n",
       "                            </td>\n",
       "                            <td style=\"text-align: left;\">\n",
       "                                <strong>Total threads:</strong>\n",
       "                                32\n",
       "                            </td>\n",
       "                        </tr>\n",
       "                        <tr>\n",
       "                            <td style=\"text-align: left;\">\n",
       "                                <strong>Started:</strong>\n",
       "                                Just now\n",
       "                            </td>\n",
       "                            <td style=\"text-align: left;\">\n",
       "                                <strong>Total memory:</strong>\n",
       "                                251.65 GiB\n",
       "                            </td>\n",
       "                        </tr>\n",
       "                    </table>\n",
       "                </div>\n",
       "            </div>\n",
       "        \n",
       "            <details style=\"margin-left: 48px;\">\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Workers</h3></summary>\n",
       "            \n",
       "            <div style=\"margin-bottom: 20px;\">\n",
       "                <div style=\"width: 24px;\n",
       "                            height: 24px;\n",
       "                            background-color: #DBF5FF;\n",
       "                            border: 3px solid #4CC9FF;\n",
       "                            border-radius: 5px;\n",
       "                            position: absolute;\"> </div>\n",
       "                <div style=\"margin-left: 48px;\">\n",
       "                <details>\n",
       "                    <summary>\n",
       "                        <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 0</h4>\n",
       "                    </summary>\n",
       "                    <table style=\"width: 100%; text-align: left;\">\n",
       "                        <tr>\n",
       "                            <td style=\"text-align: left;\"><strong>Comm: </strong> tcp://127.0.0.1:33757</td>\n",
       "                            <td style=\"text-align: left;\"><strong>Total threads: </strong> 32</td>\n",
       "                        </tr>\n",
       "                        <tr>\n",
       "                            <td style=\"text-align: left;\">\n",
       "                                <strong>Dashboard: </strong>\n",
       "                                <a href=\"http://127.0.0.1:34887/status\">http://127.0.0.1:34887/status</a>\n",
       "                            </td>\n",
       "                            <td style=\"text-align: left;\">\n",
       "                                <strong>Memory: </strong>\n",
       "                                251.65 GiB\n",
       "                            </td>\n",
       "                        </tr>\n",
       "                        <tr>\n",
       "                            <td style=\"text-align: left;\"><strong>Nanny: </strong> tcp://127.0.0.1:35957</td>\n",
       "                            <td style=\"text-align: left;\"></td>\n",
       "                        </tr>\n",
       "                        <tr>\n",
       "                            <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                                <strong>Local directory: </strong>\n",
       "                                /data/airline_delay_causal/dask-worker-space/worker-7du86sc8\n",
       "                            </td>\n",
       "                        </tr>\n",
       "                        \n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>GPU: </strong>Quadro RTX 8000\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>GPU memory: </strong>\n",
       "                        47.46 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "                \n",
       "                        \n",
       "                    </table>\n",
       "                </details>\n",
       "                </div>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        </div>\n",
       "        \n",
       "                    </details>\n",
       "                </div>\n",
       "            </div>\n",
       "        \n",
       "                </details>\n",
       "                \n",
       "                </div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:38995' processes=1 threads=32, memory=251.65 GiB>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, wait, progress, get_worker\n",
    "\n",
    "print('dask version', dask.__version__)\n",
    "\n",
    "# Load external tables for merging:\n",
    "staging_dir = './data/staging_tbl/'\n",
    "etl_output_dir = './data/encoded/NAS/' # Directory will be wiped!\n",
    "\n",
    "try:\n",
    "    # RECURSIVELY DELETE DIRECTORY and then add it\n",
    "    shutil.rmtree(etl_output_dir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "os.mkdir(etl_output_dir)\n",
    "\n",
    "# Small number of workers okay for ETL to reserve more mem per worker. Most tasks are threaded.\n",
    "client = Client(n_workers=1, threads_per_worker=32) # Good for DSWS.\n",
    "# client = Client('tcp://192.168.1.232:8786') # Connect to dask-scheduler\n",
    "\n",
    "# Working config for full 17 year data set: 1w32t, 256GB RAM. Peak mem usage around 225GB, including spill with repartition between joins.\n",
    "# Default spill is at 60% worker's mem usage. Spilling to disk adversely affects performance. Can also disable spill.\n",
    "# Currently use repartitioning before each join to optimize joins.\n",
    "\n",
    "def disable_spill():\n",
    "    dask.config.set({'distributed.worker.memory.target': False, \n",
    "    'distributed.worker.memory.spill': False, \n",
    "    'distributed.worker.memory.pause': 0.95,\n",
    "    'distributed.worker.memory.terminate': 0.97}\n",
    "    )\n",
    "    print(dask.config.config)\n",
    "    \n",
    "client.register_worker_callbacks(setup=disable_spill)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f7d054-2049-44a7-b910-c21c5066a35b",
   "metadata": {},
   "source": [
    "Airport demand and airport weather partitioned by airport. This ensures that external tables are smaller than main table for the big.merge(small) patterned joins with sorted data. Smaller table can fit within memory and be broadcasted. Tried to perform partitioning by year with 8 parquet files per year (17*8 files), which failed on first full year merge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb92bea0-b573-4225-8560-b633f68b03ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 142 ms, sys: 95.5 ms, total: 238 ms\n",
      "Wall time: 376 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "run_type = 'cpu'\n",
    "\n",
    "if run_type == 'gpu':\n",
    "    import dask_cudf as hw\n",
    "else:\n",
    "    import dask.dataframe as hw\n",
    "\n",
    "arpt_demand_dd = hw.read_parquet(staging_dir+'arpt_demand')\n",
    "arpt_weather_dd = hw.read_parquet(staging_dir+'arpt_weather')\n",
    "nas_flights_dd = hw.read_parquet(staging_dir+'nas_flights')\n",
    "\n",
    "\n",
    "# # Pre-filter data for testing:\n",
    "# test_arpt = 'ATL_GA'\n",
    "# arpt_demand_dd = arpt_demand_dd[arpt_demand_dd['ARPT_NAME']==test_arpt]\n",
    "# arpt_weather_dd = arpt_weather_dd[arpt_weather_dd['ARPT_NAME']==test_arpt]\n",
    "# nas_flights_dd = nas_flights_dd[nas_flights_dd['ORIGIN']==test_arpt]\n",
    "\n",
    "\n",
    "# Convert partitioned columns to str for merging:\n",
    "arpt_demand_dd['ARPT_NAME'] = arpt_demand_dd['ARPT_NAME'].astype('category')\n",
    "arpt_weather_dd['ARPT_NAME'] = arpt_weather_dd['ARPT_NAME'].astype('category')\n",
    "nas_flights_dd['ORIGIN'] = nas_flights_dd['ORIGIN'].astype('category')\n",
    "\n",
    "arpt_demand_dd['YEAR'] = arpt_demand_dd['YEAR'].astype('int16')\n",
    "arpt_weather_dd['YEAR'] = arpt_weather_dd['YEAR'].astype('int16')\n",
    "nas_flights_dd['YEAR'] = nas_flights_dd['YEAR'].astype('int16')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3bab15c-5a14-4038-a19f-c5ec680c2bd0",
   "metadata": {},
   "source": [
    "# Merge airport demand and weather since they are aligned on ARPT_NAME. \n",
    "# Flights have two airports of interest (ORIGIN/DEST) so alignment not possible. Use YYYYMM or YEAR instead.\n",
    "\n",
    "arpt_demand_dd['DT_LOCAL_HR'] = arpt_demand_dd['DT_LOCAL_QTHR'].dt.hour\n",
    "\n",
    "arpt_demand_dd.merge(arpt_weather_dd, on=['ARPT_NAME', 'DT_LOCAL_HR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f94448d1-496f-45a2-be15-7c712fd030e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/IPython/core/magics/execution.py\", line 1321, in time\n",
      "    exec(code, glob, local_ns)\n",
      "  File \"<timed exec>\", line 88, in <module>\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/dask/dataframe/core.py\", line 4389, in to_parquet\n",
      "    return to_parquet(self, path, *args, **kwargs)\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\", line 653, in to_parquet\n",
      "    out = out.compute(**compute_kwargs)\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/dask/base.py\", line 285, in compute\n",
      "    (result,) = compute(self, traverse=False, **kwargs)\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/dask/base.py\", line 567, in compute\n",
      "    results = schedule(dsk, keys, **kwargs)\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/distributed/client.py\", line 2705, in get\n",
      "    results = self.gather(packed, asynchronous=asynchronous, direct=direct)\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/distributed/client.py\", line 2014, in gather\n",
      "    return self.sync(\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/distributed/client.py\", line 855, in sync\n",
      "    return sync(\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/distributed/utils.py\", line 335, in sync\n",
      "    e.wait(10)\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/threading.py\", line 558, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/threading.py\", line 306, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m                 \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(self, path, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4389\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, write_index, append, overwrite, ignore_divisions, partition_on, storage_options, custom_metadata, write_metadata_file, compute, compute_kwargs, schema, **kwargs)\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[0mcompute_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcompute_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \"\"\"\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, dsk, keys, workers, allow_other_workers, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   2704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2705\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2706\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   2013\u001b[0m                 \u001b[0mlocal_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2014\u001b[0;31m             return self.sync(\n\u001b[0m\u001b[1;32m   2015\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m             return sync(\n\u001b[0m\u001b[1;32m    856\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f19055f09595>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nif run_type == \\'gpu\\':\\n    # BLOCKING issue: GPU has merge issues related to categorical/object columns. It\\'s trying to cast everything to numeric.\\n    # Possible issue with datetime object and categoricals in cudf?\\n    \\n    arpt_demand_dd = hw.read_parquet(staging_dir+\\'arpt_demand\\', columns=[\\'YEAR\\', \\'ARR_PER_QTHR\\'])\\n    nas_flights_dd = hw.read_parquet(staging_dir+\\'nas_flights\\', columns=[\\'YEAR\\', \\'ORIGIN\\', \\'DEP_DELAY\\'])\\n    \\n    # Fix dtype for autotype YEAR partition:\\n    arpt_demand_dd[\\'YEAR\\'] = arpt_demand_dd[\\'YEAR\\'].astype(\\'int16\\')\\n    nas_flights_dd[\\'YEAR\\'] = nas_flights_dd[\\'YEAR\\'].astype(\\'int16\\')\\n    \\n    arpt_demand_dd = arpt_demand_dd[arpt_demand_dd[\\'YEAR\\']==2003]\\n    nas_flights_dd = nas_flights_dd[nas_flights_dd[\\'YEAR\\']==2003]\\n    \\n    arpt_demand_dd = arpt_demand_dd.reset_index()\\n    arpt_demand_dd[\\'ARPT_NAME\\'] = arpt_demand_dd[\\'ARPT_NAME\\'].astype(str)\\n    nas_flights_dd[\\'ORIGIN\\'] = nas_flights_dd[\\'ORIGIN\\'].astype(str)\\n    \\n    nas_flights_mg = nas_flights_dd.merge(arpt_demand_dd, left_on=[\\'YEAR\\', \\'ORIGIN\\'], \\n                                          right_on=[\\'YEAR\\', \\'ARPT_NAME\\'], how=\\'left\\')\\n\\nelse:\\n    # Generate computational graph for entire merging pipeline. Let dask manage tasks.\\n    \\n    # Repartition data after each join to reduce overhead: https://docs.dask.org/en/latest/dataframe-best-practices.html#repartition-to-reduce-overhead\\n    # \"Reducing partitions is very helpful just before shuffling, which creates n log(n) tasks relative to the number of partitions. \\n    # DataFrames with less than 100 partitions are much easier to shuffle than DataFrames with tens of thousands.\"\\n    npartitions = 256 # Number of airports ~400 in full data.\\n    \\n    #############################\\n    ## Merge ORIGIN Attributes ##\\n    #############################\\n    # dd.add_prefix() works on dask 2021.06.1 but not 2021.05.1?\\n    nas_flights_mg = nas_flights_dd.merge(arpt_demand_dd.add_prefix(\\'ORIGIN_\\'), left_on=[\\'ORIGIN\\', \\'DEP_TIME_DT_LOCAL_QTHR\\'], \\n                                      right_on=[\\'ORIGIN_ARPT_NAME\\', \\'ORIGIN_DT_LOCAL_QTHR\\'], how=\\'left\\').drop(columns=[\\'ORIGIN_YEAR\\', \\'ORIGIN_ARPT_NAME\\'])\\n#     nas_flights_mg = nas_flights_mg.repartition(npartitions=npartitions).persist()\\n    \\n    # Merge weather data at origin and destination. INNER join used to remove records without weather data. Or left join to keep and remove NA\\'s later.\\n    # Assumed that hourly weather data at all airports are complete. A small fraction of airports don\\'t have corresponding weather station.\\n    # Weather data merge is most time consuming step. Need to scatter weather tables?\\n    wx_join_type = \\'left\\'\\n    nas_flights_mg = nas_flights_mg.merge(arpt_weather_dd.add_prefix(\\'ORIGIN_\\'), left_on=[\\'ORIGIN\\', \\'DEP_TIME_DT_LOCAL_HR\\'],\\n                                          right_on=[\\'ORIGIN_ARPT_NAME\\', \\'ORIGIN_DT_LOCAL_HR\\'], how=wx_join_type).drop(columns=[\\'ORIGIN_YEAR\\', \\'ORIGIN_ARPT_NAME\\'])\\n#     nas_flights_mg = nas_flights_mg.repartition(npartitions=npartitions).persist()\\n    \\n    ###########################\\n    ## Merge DEST Attributes ##\\n    ###########################\\n    nas_flights_mg = nas_flights_mg.merge(arpt_demand_dd.add_prefix(\\'DEST_\\'), left_on=[\\'DEST\\', \\'ARR_TIME_DT_LOCAL_QTHR\\'], \\n                                          right_on=[\\'DEST_ARPT_NAME\\', \\'DEST_DT_LOCAL_QTHR\\'], how=\\'left\\').drop(columns=[\\'DEST_YEAR\\', \\'DEST_ARPT_NAME\\'])\\n#     nas_flights_mg = nas_flights_mg.repartition(npartitions=npartitions).persist()\\n    \\n    nas_flights_mg = nas_flights_mg.merge(arpt_weather_dd.add_prefix(\\'DEST_\\'), left_on=[\\'DEST\\', \\'ARR_TIME_DT_LOCAL_HR\\'], \\n                                      right_on=[\\'DEST_ARPT_NAME\\', \\'DEST_DT_LOCAL_HR\\'], how=wx_join_type).drop(columns=[\\'DEST_YEAR\\', \\'DEST_ARPT_NAME\\'])\\n#     nas_flights_mg = nas_flights_mg.repartition(npartitions=npartitions).persist() # Don\\'t need to repartition after last merge.\\n    \\n    arpt_demand_attr_cols = [cc for cc in arpt_demand_dd.columns if cc not in [\\'YEAR\\', \\'ARPT_NAME\\', \\'DT_LOCAL_QTHR\\']]\\n    arpt_demand_attr_cols = [prefix + dcols for prefix in [\\'ORIGIN_\\', \\'DEST_\\'] for dcols in arpt_demand_attr_cols]\\n#     print(\\'Airport demand cols:\\', arpt_demand_attr_cols)\\n\\n    # Fill missing data due to merging:\\n    nas_flights_mg[arpt_demand_attr_cols] = nas_flights_mg[arpt_demand_attr_cols].fillna(0).astype(\\'int8\\')\\n    \\n    # Due to sporadic weather data, missing fields can only be dropped instead of imputed.\\n\\n    # Remove certain cols with ORIGIN_/DEST_ prefix:\\n    od_remove_cols = [\\'DT_LOCAL_QTHR\\', \\'DT_LOCAL_HR\\']\\n    od_remove_cols = [pfix+cc for pfix in [\\'ORIGIN_\\', \\'DEST_\\'] for cc in od_remove_cols]\\n\\n    # Remove certain cols with ARR/DEP_ prefix:\\n    ad_remove_cols = [\\'TIME_DT_LOCAL\\', \\'TIME_DT_LOCAL_DAY\\', \\'TIME_DT_LOCAL_HR\\', \\'TIME_DT_LOCAL_QTHR\\']\\n    ad_remove_cols = [pfix+cc for pfix in [\\'ARR_\\', \\'DEP_\\'] for cc in ad_remove_cols]\\n\\n    # Drop unecessary columns to prevent leakage and duplicate data:\\n    nas_flights_mg = nas_flights_mg.drop(columns=ad_remove_cols + od_remove_cols)\\n\\n    # Cast to float32 so parquet file can be written. Newer version of pyarrow supports float16.\\n    fp16_cols = list(nas_flights_mg.select_dtypes(\\'float16\\').columns)\\n    nas_flights_mg[fp16_cols] = nas_flights_mg[fp16_cols].astype(\\'float32\\')\\n    \\n    # Performance penalty of 25-50% when external table (e.g., weather data) has categorical features. Should leave them as objects then categorize() after merge.\\n    # categorize forces computation so would need to checkpoint data before .categorize(). \\n    # Defer running .categorize() until final merge and/or encoding step.\\n#     nas_flights_mg = nas_flights_mg.categorize() # categorize() converts all \\'object\\' cols to \\'category\\'. And unknown categories to known.\\n    \\n    # Data was aligned on airport for ease of merging. Need to partition data on YYYYMM to quickly access files for time-series test/train split and cross-validation. \\n    # Use write_metadata_file=False to avoid writing the two metadata folders. Dask cannot read partitioned directory with metadata files included.\\n    nas_flights_mg.repartition(npartitions=1).to_parquet(etl_output_dir, write_metadata_file=False, partition_on=[\\'YYYYMM\\'], flavor=\\'spark\\')\\n#     nas_flights_mg.to_parquet(etl_output_dir, write_metadata_file=False, partition_on=[\\'YYYYMM\\'], flavor=\\'spark\\')\\n\\n    \\n# len(nas_flights_mg)\\n# nas_flights_mg.head(5) # Head completes much faster than len(). Dask may just be computing a small subset of data to display.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2401\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2402\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2403\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2404\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1326\u001b[0m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2061\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2064\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if run_type == 'gpu':\n",
    "    # BLOCKING issue: GPU has merge issues related to categorical/object columns. It's trying to cast everything to numeric.\n",
    "    # Possible issue with datetime object and categoricals in cudf?\n",
    "    \n",
    "    arpt_demand_dd = hw.read_parquet(staging_dir+'arpt_demand', columns=['YEAR', 'ARR_PER_QTHR'])\n",
    "    nas_flights_dd = hw.read_parquet(staging_dir+'nas_flights', columns=['YEAR', 'ORIGIN', 'DEP_DELAY'])\n",
    "    \n",
    "    # Fix dtype for autotype YEAR partition:\n",
    "    arpt_demand_dd['YEAR'] = arpt_demand_dd['YEAR'].astype('int16')\n",
    "    nas_flights_dd['YEAR'] = nas_flights_dd['YEAR'].astype('int16')\n",
    "    \n",
    "    arpt_demand_dd = arpt_demand_dd[arpt_demand_dd['YEAR']==2003]\n",
    "    nas_flights_dd = nas_flights_dd[nas_flights_dd['YEAR']==2003]\n",
    "    \n",
    "    arpt_demand_dd = arpt_demand_dd.reset_index()\n",
    "    arpt_demand_dd['ARPT_NAME'] = arpt_demand_dd['ARPT_NAME'].astype(str)\n",
    "    nas_flights_dd['ORIGIN'] = nas_flights_dd['ORIGIN'].astype(str)\n",
    "    \n",
    "    nas_flights_mg = nas_flights_dd.merge(arpt_demand_dd, left_on=['YEAR', 'ORIGIN'], \n",
    "                                          right_on=['YEAR', 'ARPT_NAME'], how='left')\n",
    "\n",
    "else:\n",
    "    # Generate computational graph for entire merging pipeline. Let dask manage tasks.\n",
    "    \n",
    "    # Repartition data after each join to reduce overhead: https://docs.dask.org/en/latest/dataframe-best-practices.html#repartition-to-reduce-overhead\n",
    "    # \"Reducing partitions is very helpful just before shuffling, which creates n log(n) tasks relative to the number of partitions. \n",
    "    # DataFrames with less than 100 partitions are much easier to shuffle than DataFrames with tens of thousands.\"\n",
    "    npartitions = 256 # Number of airports ~400 in full data.\n",
    "    \n",
    "    #############################\n",
    "    ## Merge ORIGIN Attributes ##\n",
    "    #############################\n",
    "    # dd.add_prefix() works on dask 2021.06.1 but not 2021.05.1?\n",
    "    nas_flights_mg = nas_flights_dd.merge(arpt_demand_dd.add_prefix('ORIGIN_'), left_on=['ORIGIN', 'DEP_TIME_DT_LOCAL_QTHR'], \n",
    "                                      right_on=['ORIGIN_ARPT_NAME', 'ORIGIN_DT_LOCAL_QTHR'], how='left').drop(columns=['ORIGIN_YEAR', 'ORIGIN_ARPT_NAME'])\n",
    "#     nas_flights_mg = nas_flights_mg.repartition(npartitions=npartitions).persist()\n",
    "    \n",
    "    # Merge weather data at origin and destination. INNER join used to remove records without weather data. Or left join to keep and remove NA's later.\n",
    "    # Assumed that hourly weather data at all airports are complete. A small fraction of airports don't have corresponding weather station.\n",
    "    # Weather data merge is most time consuming step. Need to scatter weather tables?\n",
    "    wx_join_type = 'left'\n",
    "    nas_flights_mg = nas_flights_mg.merge(arpt_weather_dd.add_prefix('ORIGIN_'), left_on=['ORIGIN', 'DEP_TIME_DT_LOCAL_HR'],\n",
    "                                          right_on=['ORIGIN_ARPT_NAME', 'ORIGIN_DT_LOCAL_HR'], how=wx_join_type).drop(columns=['ORIGIN_YEAR', 'ORIGIN_ARPT_NAME'])\n",
    "#     nas_flights_mg = nas_flights_mg.repartition(npartitions=npartitions).persist()\n",
    "    \n",
    "    ###########################\n",
    "    ## Merge DEST Attributes ##\n",
    "    ###########################\n",
    "    nas_flights_mg = nas_flights_mg.merge(arpt_demand_dd.add_prefix('DEST_'), left_on=['DEST', 'ARR_TIME_DT_LOCAL_QTHR'], \n",
    "                                          right_on=['DEST_ARPT_NAME', 'DEST_DT_LOCAL_QTHR'], how='left').drop(columns=['DEST_YEAR', 'DEST_ARPT_NAME'])\n",
    "#     nas_flights_mg = nas_flights_mg.repartition(npartitions=npartitions).persist()\n",
    "    \n",
    "    nas_flights_mg = nas_flights_mg.merge(arpt_weather_dd.add_prefix('DEST_'), left_on=['DEST', 'ARR_TIME_DT_LOCAL_HR'], \n",
    "                                      right_on=['DEST_ARPT_NAME', 'DEST_DT_LOCAL_HR'], how=wx_join_type).drop(columns=['DEST_YEAR', 'DEST_ARPT_NAME'])\n",
    "#     nas_flights_mg = nas_flights_mg.repartition(npartitions=npartitions).persist() # Don't need to repartition after last merge.\n",
    "    \n",
    "    arpt_demand_attr_cols = [cc for cc in arpt_demand_dd.columns if cc not in ['YEAR', 'ARPT_NAME', 'DT_LOCAL_QTHR']]\n",
    "    arpt_demand_attr_cols = [prefix + dcols for prefix in ['ORIGIN_', 'DEST_'] for dcols in arpt_demand_attr_cols]\n",
    "#     print('Airport demand cols:', arpt_demand_attr_cols)\n",
    "\n",
    "    # Fill missing data due to merging:\n",
    "    nas_flights_mg[arpt_demand_attr_cols] = nas_flights_mg[arpt_demand_attr_cols].fillna(0).astype('int8')\n",
    "    \n",
    "    # Due to sporadic weather data, missing fields can only be dropped instead of imputed.\n",
    "\n",
    "    # Remove certain cols with ORIGIN_/DEST_ prefix:\n",
    "    od_remove_cols = ['DT_LOCAL_QTHR', 'DT_LOCAL_HR']\n",
    "    od_remove_cols = [pfix+cc for pfix in ['ORIGIN_', 'DEST_'] for cc in od_remove_cols]\n",
    "\n",
    "    # Remove certain cols with ARR/DEP_ prefix:\n",
    "    ad_remove_cols = ['TIME_DT_LOCAL', 'TIME_DT_LOCAL_DAY', 'TIME_DT_LOCAL_HR', 'TIME_DT_LOCAL_QTHR']\n",
    "    ad_remove_cols = [pfix+cc for pfix in ['ARR_', 'DEP_'] for cc in ad_remove_cols]\n",
    "\n",
    "    # Drop unecessary columns to prevent leakage and duplicate data:\n",
    "    nas_flights_mg = nas_flights_mg.drop(columns=ad_remove_cols + od_remove_cols)\n",
    "\n",
    "    # Cast to float32 so parquet file can be written. Newer version of pyarrow supports float16.\n",
    "    fp16_cols = list(nas_flights_mg.select_dtypes('float16').columns)\n",
    "    nas_flights_mg[fp16_cols] = nas_flights_mg[fp16_cols].astype('float32')\n",
    "    \n",
    "    # Performance penalty of 25-50% when external table (e.g., weather data) has categorical features. Should leave them as objects then categorize() after merge.\n",
    "    # categorize forces computation so would need to checkpoint data before .categorize(). \n",
    "    # Defer running .categorize() until final merge and/or encoding step.\n",
    "#     nas_flights_mg = nas_flights_mg.categorize() # categorize() converts all 'object' cols to 'category'. And unknown categories to known.\n",
    "    \n",
    "    # Data was aligned on airport for ease of merging. Need to partition data on YYYYMM to quickly access files for time-series test/train split and cross-validation. \n",
    "    # Use write_metadata_file=False to avoid writing the two metadata folders. Dask cannot read partitioned directory with metadata files included.\n",
    "    nas_flights_mg.repartition(npartitions=1).to_parquet(etl_output_dir, write_metadata_file=False, partition_on=['YYYYMM'], flavor='spark')\n",
    "#     nas_flights_mg.to_parquet(etl_output_dir, write_metadata_file=False, partition_on=['YYYYMM'], flavor='spark')\n",
    "\n",
    "    \n",
    "# len(nas_flights_mg)\n",
    "# nas_flights_mg.head(5) # Head completes much faster than len(). Dask may just be computing a small subset of data to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1872e94a-083f-430b-8561-b37fe1be5243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TargetEncoder needs to be applied after test/train split to avoid leakage. \n",
    "# TargetEncoder from category_encoder doesn't understand dask.dataframe. Pandas required, but entire data may not fit within mem.\n",
    "# Need to slice UID and categorical/object cols to encode. Then merge with full data prior to running training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b71f802-3993-4a95-9081-9cf5a34a9822",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe61d28-b954-496f-9bf9-a1e5414ee6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_df = dd.read_parquet(etl_output_dir)\n",
    "print(len(enc_df))\n",
    "enc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ed6155-31b9-4130-b6f6-fae53262f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure data doesn't contain NA's:\n",
    "na_count = enc_df.isna().sum()\n",
    "\n",
    "# Encoded data quality check:\n",
    "qc_out = pd.DataFrame({'dtype': enc_df.dtypes, 'NA_cnt': na_count})\n",
    "qc_out.sort_values('NA_cnt', ascending=False)\n",
    "\n",
    "# Certain airports does not contain weather data. These can be dropped before running ML pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5681c84e-42e7-45a2-9706-d6dc7daaf0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dtypes. Should not have datetime after pre-encoding. Okay to have category and object cols.\n",
    "qc_out['dtype'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728d0b4f-33c3-4c11-9c80-8f0dbca5a330",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(nas_flights_mg.columns, nas_flights_mg.dtypes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
