{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61557253-e3dc-4ca8-a9e7-b8e39e0af37a",
   "metadata": {},
   "source": [
    "# XGBOOST Model Applications\n",
    "The trained and validated model can be used to make predictions on unlabeled data. For example, we can use it on the 'predict_past' data set that corresponds to data prior to June 2003 (when delay causes were not included with the flight records). This enables us to make the database consistent and enables other applications that require delay attribution to be look further back in time. Similarly, new data (actual or simulated) can be labelled based on the trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74cde2f6-2908-479e-9103-aa3cf9df90cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost version 1.5.0-dev\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:37561</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>32</li>\n",
       "  <li><b>Memory: </b>251.65 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:37561' processes=1 threads=32, memory=251.65 GiB>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import numpy as np\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, wait, progress, get_worker\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost.dask import DaskDMatrix\n",
    "\n",
    "print('xgboost version', xgb.__version__)\n",
    "\n",
    "run_type = 'cpu'\n",
    "max_depth = 10\n",
    "num_boost_round = 200\n",
    "score_metric = 'auc'\n",
    "storage_backend = 'local'\n",
    "\n",
    "test_size = 1/17 # Non-zero to pass data split check. \n",
    "   \n",
    "study_arpt = 'NAS'\n",
    "\n",
    "if study_arpt == 'NAS':\n",
    "    # NAS processing excludes weather. Has additional cols for arrival/departure airports.\n",
    "    pred_model = 'multi_class'\n",
    "    label_col = 'DELAY_CAUSES_ENC'\n",
    "    excluded_features = [label_col, 'cv_idx', 'UID', 'ARR_DEL15', 'DEP_DEL15', 'YYYYMM']\n",
    "else:\n",
    "    pred_model = 'binary_class'\n",
    "    label_col = 'ARR_DEL15'\n",
    "    excluded_features = [label_col, 'cv_idx', 'UID', 'DEL_ARR_PER_QTHR', 'DEL_DEP_PER_QTHR', 'DEP_DEL15', 'ARR_DEL']\n",
    "\n",
    "if pred_model == 'binary_class':\n",
    "    xgb_objective = 'binary:logistic'\n",
    "elif pred_model == 'multi_class':\n",
    "    # xgboost auc docs mentioned that: \"When used with multi-class classification, objective should be multi:softprob instead of multi:softmax, \n",
    "    # as the latter doesn’t output probability. Also the AUC is calculated by 1-vs-rest with reference class weighted by class prevalence.\"\n",
    "    xgb_objective = 'multi:softprob'\n",
    "# elif pred_model == 'regression':\n",
    "#     label_col = 'ARR_DELAY' # Regression model\n",
    "#     xgb_objective = 'reg:squarederror'\n",
    "    \n",
    "partial_enc_input_dir = './data/encoded/'+study_arpt # Partially encoded data. Target encoding required.\n",
    "enc_output_dir = './data/encoded/split/'+study_arpt\n",
    "\n",
    "xgb_model_name = 'xgb_'+run_type+'_airline_delay_'+study_arpt+'_max_depth_'+str(max_depth)\n",
    "\n",
    "# client = Client('tcp://192.168.1.232:8786')\n",
    "\n",
    "if run_type == 'gpu':\n",
    "    from dask_cuda import LocalCUDACluster\n",
    "    \n",
    "    # Run on all available GPU on same machine:\n",
    "    cluster = LocalCUDACluster(threads_per_worker=16, memory_limit='128GB')\n",
    "    client = Client(cluster)\n",
    "    \n",
    "    # Run single GPU:\n",
    "#     client = Client(n_workers=1, threads_per_worker=32)\n",
    "elif run_type == 'cpu':\n",
    "    client = Client(n_workers=1, threads_per_worker=32)    \n",
    "    \n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e805f32f-1f82-48a7-8714-4fe85437e165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.4 s, sys: 1.14 s, total: 3.54 s\n",
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def dask_xgb_predict_output(client, run_type, model_file, data_path, label_col):\n",
    "    \"\"\"\n",
    "    Use dask + xgboost for inferencing against already encoded data.\n",
    "    \"\"\"    \n",
    "    if run_type == 'gpu':\n",
    "        import dask_cudf as hw # Needed for xgb.dask.inplace_predict(). \n",
    "#         import dask.dataframe as hw # Has internal switching for compatibility. Takes a long time to perform AUC score, but fast at prediction.\n",
    "    else:\n",
    "        import dask.dataframe as hw\n",
    "    \n",
    "    model = xgb.Booster(model_file=model_file+'.model')\n",
    "    \n",
    "    ddf_enc = hw.read_parquet(data_path).persist()\n",
    "\n",
    "    # Format data for xgboost:\n",
    "    feature_cols = [cc for cc in ddf_enc.columns if cc not in excluded_features]\n",
    "    X = ddf_enc[feature_cols].astype('float32')\n",
    "    y = ddf_enc[label_col].astype('float32')\n",
    "\n",
    "    # Run predictions:\n",
    "    tic = time()\n",
    "    model.set_param('predictor', run_type + '_predictor')\n",
    "    model = client.scatter(model, broadcast=True)\n",
    "\n",
    "    # IMPORTANT: X.values required to get consistent CPU scoring. Issue with column ordering in dask.dataframe?\n",
    "    y_pred = xgb.dask.inplace_predict(client, model, X.values) # Use inplace_predict() can sometimes be faster.\n",
    "\n",
    "    # Force computation of y's required for libraries without dask.dataframe support:\n",
    "    y_pred = y_pred.compute()\n",
    "    y = y.compute()\n",
    "\n",
    "    predict_time = np.round(time() - tic, 2)\n",
    "    gc.collect()\n",
    "    return(y_pred, y)\n",
    "\n",
    "\n",
    "y_pred, y = dask_xgb_predict_output(client, run_type, xgb_model_name, enc_output_dir+'/test', label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c177c0b-88bf-41e8-89da-fd928af62b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9821772276728551"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_pred(run_type, y_true, y_pred, score_metric):\n",
    "    \"\"\"\n",
    "    Prediction scoring function.\n",
    "    \"\"\"\n",
    "    if pred_model == 'multi_class':\n",
    "        # Scoring for multi-class is done on CPU only. cuML roc_auc_score doesn't not work with multi-class yet.\n",
    "        # Work-around is to use CPU for scoring via converting gpu-dataframe to pandas.\n",
    "        if run_type == 'gpu':\n",
    "            import cupy\n",
    "            y_true = cupy.asnumpy(y_true)\n",
    "            y_pred = cupy.asnumpy(y_pred)\n",
    "            \n",
    "            # Update run_type to bypass GPU methods.\n",
    "            run_type = 'cpu'\n",
    "    \n",
    "    if run_type == 'gpu':\n",
    "#         import dask.dataframe as hw # Has internal switching for compatibility. Takes a long time to perform AUC score, but fast at prediction.\n",
    "        from cuml.metrics import roc_auc_score\n",
    "        from cuml.metrics.accuracy import accuracy_score\n",
    "        # TODO: inplace scoring to pair with inplace prediction? Only works with certain methods.\n",
    "    else:\n",
    "        # TODO: need parallelized roc_auc_score computation for auc.\n",
    "        from sklearn.metrics import roc_auc_score # Single-threaded?\n",
    "#         from sklearn.metrics import accuracy_score # Single-threaded\n",
    "        from dask_ml.metrics import accuracy_score # CPU parallelized\n",
    "\n",
    "    if score_metric == 'auc':\n",
    "        if pred_model == 'multi_class':\n",
    "            # xgb multi-class classification uses One-vs-Rest (or One-vs-All): \n",
    "            score_value = roc_auc_score(y_true, y_pred, multi_class='ovr', average='macro')\n",
    "            \n",
    "            # Only support average param of: \n",
    "                # 'macro' (default): Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.)\n",
    "                # 'weighted': Calculate metrics for each label, and find their average, weighted by support (the number of true instances for each label).\n",
    "                \n",
    "            # Use average='macro' so model takes extreme imbalance of minority classes into consideration within score.\n",
    "        else:\n",
    "            # AUC uses probabilities. https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "            score_value = roc_auc_score(y_true, y_pred)\n",
    "    elif score_metric == 'acc':\n",
    "        # Accuracy score uses threshold value due to ==. https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "        score_value = accuracy_score(y_true.round(), y_pred.round()) # y_pred needs to be converted explicitly. Dask doesn't know shape of y, y_pred if dask.dataframe.\n",
    "    return(score_value)\n",
    "\n",
    "score_pred(run_type, y, y_pred, 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a2be1a3-7e11-49ff-891d-d544e72cbf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred_class</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537240</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537241</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537242</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537243</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537244</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7010951 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        y_true  y_pred_class  match\n",
       "0            0             0   True\n",
       "1            0             0   True\n",
       "2            0             0   True\n",
       "3            0             0   True\n",
       "4            0             0   True\n",
       "...        ...           ...    ...\n",
       "537240       0             0   True\n",
       "537241       0             0   True\n",
       "537242       0             0   True\n",
       "537243       0             0   True\n",
       "537244       5             2  False\n",
       "\n",
       "[7010951 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine most likely class based on individual binary predictions:\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "\n",
    "test_pred = pd.DataFrame({'y_true': y, 'y_pred_class': y_pred_class})\n",
    "test_pred['y_true'] = test_pred['y_true'].astype(int)\n",
    "test_pred['match'] = test_pred['y_true'] == test_pred['y_pred_class']\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46ea4ecc-923f-47f0-b3cf-6cb9199f1168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ----       1.00      1.00      1.00   5769760\n",
      "        --N-       0.81      0.73      0.77    260960\n",
      "        -C--       0.47      0.56      0.51    183386\n",
      "        LC--       0.49      0.34      0.40    184291\n",
      "        L---       0.46      0.50      0.48    173666\n",
      "        -CN-       0.50      0.58      0.53    131241\n",
      "        L-N-       0.43      0.33      0.37    133254\n",
      "        LCN-       0.39      0.36      0.37     98684\n",
      "        OOOO       0.31      0.49      0.38     75709\n",
      "\n",
      "    accuracy                           0.91   7010951\n",
      "   macro avg       0.54      0.54      0.53   7010951\n",
      "weighted avg       0.92      0.91      0.91   7010951\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "num_classes = int(np.max(y)+1)\n",
    "\n",
    "meta_class_cnts = pd.read_csv('./data/staging_tbl/class_labels.csv')\n",
    "\n",
    "# Truncate at last class:\n",
    "meta_class_cnts = meta_class_cnts[:num_classes]\n",
    "class_labels = list(meta_class_cnts['CLASS_STR'].values)\n",
    "class_labels = class_labels[:-1] + ['OOOO']\n",
    "\n",
    "# Use appropriate metrics for evaluating multi-class predictions.\n",
    "print(classification_report(y, y_pred_class, target_names=class_labels))\n",
    "\n",
    "# F1 score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "# Compute confusion matrix:\n",
    "cf_matrix = confusion_matrix(y, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed9d631f-4349-4763-a9aa-7bc156c90a97",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_84542/3855349708.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12, 10)})\n",
    "\n",
    "# Applying normalize param in sklearn.metrics.confusion_matrix results in \n",
    "# normalize='pred': precision along main diag. Matrix column sums to 1.  \n",
    "# normalize='true': recall along the main diag. Matrix row sums to 1.\n",
    "cf_matrix = confusion_matrix(y, y_pred_class, normalize='true')\n",
    "\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='.2%', cmap='YlGnBu',\n",
    "           xticklabels=class_labels, yticklabels=class_labels)\n",
    "\n",
    "plt.xlabel('Predicted', fontsize=12, weight='bold')\n",
    "plt.ylabel('Actual', fontsize=12, weight='bold')\n",
    "\n",
    "# Original class labels based on ranked prevalance. Based on visual inspection, we may be able to \n",
    "# reduce down to 5 meta-classes (instead of original 9) due to class overlap.\n",
    "# LATE_AIRCRAFT_DELAY and CARRIER_DELAY difficult to distinguish.\n",
    "# "
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ccea08f-5260-479b-bd7d-c9f218dbacbc",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Plotting code modified from: https://www.kaggle.com/agungor2/various-confusion-matrix-plots?scriptVersionId=12813038&cellId=4\n",
    "def plot_cm(y_true, y_pred, figsize=(12,10)):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/\\n%d' % (p, c, s)\n",
    "#                 annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "                \n",
    "    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "#     sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax)\n",
    "    \n",
    "    # Column normalized confusion matrix:\n",
    "    sns.heatmap(cm_perc, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax, \n",
    "                xticklabels=class_labels, yticklabels=class_labels\n",
    "               )\n",
    "    \n",
    "    plt.xlabel(cm.columns.name, fontsize=12, weight='bold')\n",
    "    plt.ylabel(cm.index.name, fontsize=12, weight='bold')\n",
    "    return(cm_perc)\n",
    "    \n",
    "# Results row normalized (i.e., each row adds up to 100%). Main diagonal represents recall.\n",
    "cm_perc = plot_cm(y, y_pred_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
